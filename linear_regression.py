# -*- coding: utf-8 -*-
"""Linear Regression

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1R_-MfNB_upmXGhT0o9M_C1AqqvFLbO_3
"""

from __future__ import absolute_import, division, print_function, unicode_literals

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import matplotlib.pyplot as plt
import numpy as np
from six.moves import urllib
from IPython.display import clear_output
import tensorflow.compat.v2.feature_column as fc
import pandas as pd
import time
import random as rd

x = [1,2,2.5, 3, 4]
y = [1,4,7,9,15]
plt.plot(x,y, 'ro')
plt.axis([0,6,0,20])
#plt.plot(np.unique(x), np.poly1d(np.polyfit(x,y,1))(np.unique(x))) #gambar garis
plt.show()

a = np.polyfit(x,y,5) #ekstrak fungsi polinomial dari data
print(a)

y1 = np.poly1d([1,1,1,2,3]) #fungsi y1 = x2 + 2x + 3 | bikin fungsi polinom
print(y1.o)

dftrain = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/train.csv') 
dfeval = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/eval.csv')
print(dftrain.head()) #print 5 data teratas dari data aja

y_train = dftrain.pop('survived') #pop => artinya menghilangkan kolom | hanya menampilkan kolom tertntu
y_eval = dfeval.pop('survived')

print(dftrain['age']) #seperti memanggil library
print(dftrain.loc[0]) #untuk indexing

dftrain.describe() #colllecting all of the objects statistics (mean, sum, median, min, max)

dftrain.shape #get the data size (baris x kolom)

dftrain.age.hist(bins=20) #histogram menyajikan data dengan bin, data disebar sesuai dengan jumlah bin
dftrain.age.hist(bins=5) #bins = 5 berarti cuma ada 5 bar, bins 20 brati ada 5 bar

dftrain.sex.value_counts().plot(kind='barh') #menyajikan data dalam bar horizontal

pd.concat([dftrain, y_train], axis=1).groupby('sex').survived.mean().plot(kind='barh').set_label('% survive')
#menggunakan mean dari survival rate (y_train == survived) untuk mencaritahu pembagian berdasarkan grub mana yg memiliki nilai survived paling tinggi

new = []

for i in enumerate(dftrain['class']):
  if i[1] == 'First':
    new.append(0)
  elif i[1] == 'Second':
    new.append(1)
  elif i[1] == 'Third':
    new.append(2)

print(new)

categor_col = ['sex', 'n_siblings_spouses','parch', 'class', 'deck', 'embark_town', 'alone']
numeric_col = ['age', 'fare']

feature_col = []
for feature_name in categor_col:
  vocab = dftrain[feature_name].unique() #get a list of all unique values
  print(vocab)
  feature_col.append(tf.feature_column.categorical_column_with_vocabulary_list(feature_name, vocab))

for feature_n in numeric_col:
  feature_col.append(tf.feature_column.numeric_column(feature_n, dtype = tf.float32))

print(feature_col)

"""TRAINING PROCESS =>> by feed the model

data set akan dibagi menjadi batch dan epochs

untuk membaginya maka dibutuhkan input functions
"""

def make_input_fn(data_df, label_df, num_epochs=10, shuffle=True, batch_size=32):
  def input_function(): #inner function, that'll be returned
    ds = tf.data.Dataset.from_tensor_slices((dict(data_df),label_df)) #create data object with data and label
    if shuffle:
      ds = ds.shuffle(1000) #randomize the data
    ds = ds.batch(batch_size).repeat(num_epochs)
    return ds
  return input_function

train_input_fn = make_input_fn(dftrain, y_train) #y_train =>>> label yg nanti model ML ini harus prediksi
eval_input_fn = make_input_fn(dfeval, y_eval, num_epochs=1, shuffle=False)

#RUN THE FUNCTION a.k.a Feed the ML model using tf.estimator
#create un-trained model
linear_est = tf.estimator.LinearClassifier(feature_columns=feature_col) #masukkin hasil dari vocab list

t1 = time.time()
linear_est.train(train_input_fn) #train the model with input function that already filled with feed
result = linear_est.evaluate(eval_input_fn) #evaluate the trained model
t2 = time.time()
print(t2-t1)

clear_output()
for i in result: #check the trained model spec for predictiing
  print(i, result[f'{i}'])

result = linear_est.predict(eval_input_fn) #coba memprediksi data untuk evaluate
a = list(result) #hasil prediksi dengan machine learning
print(a[0]['probabilities']) #melihat probabilitas antara survived atau dead
#terdapat 2 axis array, index 0 == probabilitas death, 1 == prob. survived
#contoh pada a[0] chance utk hidup hanya 0.091, setelah diverifikasi dengan file eval.csv nya ternyata benar
#untuk melakukan prediksi dapat menggunakan random

random_death = round(a[0]['probabilities'][0],2)
random_surv = round(a[0]['probabilities'][1],2)
chance = []
print(int(random_death*100))

for i in range(int(random_death*100)):
  chance.append(0)
for i in range(int(random_surv*100)):
  chance.append(1)

result_prediction = rd.choice(chance)
print(result_prediction)

def predict_data(model_ML, dataTarget_inputfn, index=False, Chance_Factor=2):
  result = list(model_ML.predict(dataTarget_inputfn))
  data_length = len(result)

  if not index:
    prediction_list = []
    for i in range(data_length):
      prob = result[i]['probabilities']
      value = []
      for val in enumerate(prob):
        value.append(round(prob[val[0]],int(Chance_Factor)))
      
      chance = []
      insertVal = 0
      for data in value:
        for i in range(int(data*(10**Chance_Factor))):
          chance.append(insertVal)
        insertVal += 1
      prediction_result = rd.choice(chance)
      prediction_list.append(prediction_result)
  else:
    prob = result[index]['probabilities']
    value = []
    for val in enumerate(prob):
      value.append(round(prob[val[0]],int(Chance_Factor)))
    
    chance = []
    insertVal = 0
    for data in value:
      for i in range(int(data*(10**chance_factor))):
        chance.append(insertVal)
      insertVal += 1
    prediction_list = rd.choice(chance)
  return prediction_list

result1 = predict_data(linear_est, eval_input_fn, Chance_Factor=2)
for i in result1:
  print(i)